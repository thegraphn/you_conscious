{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farm.utils import initialize_device_settings\n",
    "from farm.modeling.tokenization import Tokenizer\n",
    "from farm.data_handler.processor import TextClassificationProcessor, SquadProcessor\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.eval import Evaluator\n",
    "from farm.modeling.adaptive_model import AdaptiveModel\n",
    "from pathlib import Path\n",
    "from farm.infer import Inferencer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/graphn/repositories/you_conscious/dl_xp/data/category/train_category.tsv\",sep=\"\\t\")\n",
    "label_list_1 = df[\"label\"].tolist()\n",
    "label_list_1 = list(set(label_list_1))\n",
    "df = pd.read_csv(\"/home/graphn/repositories/you_conscious/dl_xp/data/category/test_category.tsv\",sep=\"\\t\")\n",
    "label_list_2 = df[\"label\"].tolist()\n",
    "label_list_2 = list(set(label_list_2))\n",
    "label_list = label_list_1 + label_list_2 + [\"\"]\n",
    "label_list = list(set(label_list_1+label_list_2)) \n",
    "texts = df[\"text\"].tolist()\n",
    "y_true  = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2021 06:51:53 - INFO - farm.utils -   Using device: CUDA \n",
      "04/16/2021 06:51:53 - INFO - farm.utils -   Number of GPUs: 1\n",
      "04/16/2021 06:51:53 - INFO - farm.utils -   Distributed Training: False\n",
      "04/16/2021 06:51:53 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "04/16/2021 06:51:53 - INFO - farm.modeling.language_model -   \n",
      "04/16/2021 06:51:53 - INFO - farm.modeling.language_model -   LOADING MODEL\n",
      "04/16/2021 06:51:53 - INFO - farm.modeling.language_model -   =============\n",
      "04/16/2021 06:51:53 - INFO - farm.modeling.language_model -   Model found locally at /home/graphn/repositories/you_conscious/dl_xp/trained_models/category_v1.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2021 06:51:56 - INFO - farm.modeling.language_model -   Loaded /home/graphn/repositories/you_conscious/dl_xp/trained_models/category_v1.2\n",
      "04/16/2021 06:51:56 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "04/16/2021 06:51:56 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "04/16/2021 06:51:56 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 152]\n",
      "04/16/2021 06:51:56 - INFO - farm.modeling.prediction_head -   Loading prediction head from /home/graphn/repositories/you_conscious/dl_xp/trained_models/category_v1.2/prediction_head_0.bin\n",
      "04/16/2021 06:52:01 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'DistilBertTokenizerFast'\n",
      "04/16/2021 06:52:01 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "04/16/2021 06:52:01 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "04/16/2021 06:52:01 - INFO - farm.utils -   Using device: CUDA \n",
      "04/16/2021 06:52:01 - INFO - farm.utils -   Number of GPUs: 1\n",
      "04/16/2021 06:52:01 - INFO - farm.utils -   Distributed Training: False\n",
      "04/16/2021 06:52:01 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "04/16/2021 06:52:01 - INFO - farm.infer -   Got ya 15 parallel workers to do inference ...\n",
      "04/16/2021 06:52:01 - INFO - farm.infer -    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 \n",
      "04/16/2021 06:52:01 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /|\\\n",
      "04/16/2021 06:52:01 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\  /'\\  /'\\  /'\\  /'\\  /'\\  / \\  /'\\  /'\\\n",
      "04/16/2021 06:52:01 - INFO - farm.infer -                               \n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - INFO - farm.data_handler.processor -   *** Show 1 random examples ***\n",
      "04/16/2021 06:52:01 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: None\n",
      "Clear Text: \n",
      " \ttext: nan [SEP] Avocadostore [SEP] Damen [SEP] Nae Estela | Vegane Sandaletten [SEP] Lernen Sie Estela kennen: die Blockabsatzsandalen für Damen mit einem Knotenriemen sowie mit umweltfreundlichen und OEKO- TEX-STANDARD- 100 zertifizierten Mikrofasern. Diese femininen, veganen Wildledersandalen werden in einem System frei von CO2- Emissionen hergestellt. Sie sind nicht nur hypoallergen, sondern auch antibakteriell und antimikrobiell, wodurch die Entwicklung von Gerüchen verhindert wird. Dieses Model verfügt über einen dekorativen Knoten am vorderen Riemen, einen aufsteckbaren Blockabsatz und Neolithsohlen. Die Absatzhöhe beträgt 7,5 cm. Fühlen Sie sich wohl und sicher in diesen zarten, nachhaltigen Sandalen. Sie werden in Portugal, in einem fairen Arbeitsumfeld, von Hand gefertigt. Erhältlich in Schwarz, Rot, Grün und Gelb. - 90% Mikrofasern, 10% PU- Futter (Außenmaterial); - OEKO- TEX- Standard- 100 zertifiziert; - antibakterielle, antimikrobielle und hypoallergene Auskleidung - Neolithsohlen (Synthesekautschuk); - Klopf- Blockabsatz; - in Portugal, von Hand gefertigt.\n",
      "Tokenized: \n",
      " \tNone\n",
      "Features: \n",
      " \tinput_ids: [102, 5587, 30882, 103, 9142, 1899, 20153, 3432, 30881, 103, 7617, 103, 3241, 30881, 8006, 8870, 18406, 15369, 3596, 4251, 805, 560, 106, 103, 10929, 286, 8006, 8870, 3871, 853, 128, 9298, 25019, 458, 10138, 27011, 106, 231, 7617, 212, 403, 16193, 340, 243, 686, 212, 13388, 26523, 30882, 136, 257, 17302, 30949, 232, 176, 15467, 232, 7170, 7537, 20635, 232, 1878, 24345, 8805, 6588, 22991, 566, 1100, 5379, 902, 1751, 818, 22037, 677, 106, 5767, 4455, 462, 11545, 106, 338, 153, 403, 2015, 1626, 195, 9528, 30916, 232, 23970, 7125, 566, 286, 341, 255, 475, 17986, 2616, 6990, 156, 818, 1427, 313, 8928, 3890, 17568, 1486, 136, 8928, 6120, 2029, 19931, 630, 818, 9181, 128, 1598, 195, 907, 5292, 106, 11839, 371, 566, 3077, 17232, 5352, 304, 397, 21419, 2989, 16193, 339, 22850, 5264, 243, 818, 397, 7966, 11342, 27263, 3119, 9298, 25019, 458, 136, 1042, 22579, 1230, 2548, 566, 229, 3967, 7526, 5294, 554, 818, 493, 3397, 566, 6778, 2548, 286, 251, 2134, 136, 1765, 153, 1451, 148, 1698, 818, 20511, 4251, 983, 566, 286, 338, 153, 6388, 818, 153, 403, 15644, 106, 1293, 29898, 818, 195, 1364, 15340, 566, 279, 1475, 186, 153, 6382, 818, 3667, 818, 2224, 136, 19317, 566, 232, 3543, 1227, 6588, 22991, 818, 669, 1227, 165, 30936, 232, 12545, 201, 3188, 7233, 2530, 3464, 232, 257, 17302, 30949, 232, 176, 15467, 232, 4737, 232, 1878, 24345, 3935, 3464, 232, 8928, 3890, 17568, 4078, 818, 8928, 6120, 2029, 19931, 2033, 136, 17986, 2616, 6990, 26772, 396, 21439, 232, 1042, 103]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:01 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:   0%|          | 0/40 [00:00<?, ? Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:   2%|▎         | 1/40 [00:00<00:05,  6.63 Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  12%|█▎        | 5/40 [00:00<00:03,  8.76 Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  22%|██▎       | 9/40 [00:00<00:02, 11.25 Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  32%|███▎      | 13/40 [00:00<00:01, 14.29 Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  42%|████▎     | 17/40 [00:00<00:01, 17.51 Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  52%|█████▎    | 21/40 [00:00<00:00, 20.53 Batches/s]04/16/2021 06:52:02 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  62%|██████▎   | 25/40 [00:00<00:00, 22.98 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  72%|███████▎  | 29/40 [00:00<00:00, 25.52 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  82%|████████▎ | 33/40 [00:01<00:00, 21.92 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  92%|█████████▎| 37/40 [00:01<00:00, 24.15 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:01<00:00, 28.49 Batches/s]\n",
      "Inferencing Samples:   0%|          | 0/40 [00:00<?, ? Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:   8%|▊         | 3/40 [00:00<00:01, 29.35 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  15%|█▌        | 6/40 [00:00<00:01, 29.28 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  22%|██▎       | 9/40 [00:00<00:01, 28.67 Batches/s]04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:03 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  35%|███▌      | 14/40 [00:00<00:00, 31.59 Batches/s]04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples:  45%|████▌     | 18/40 [00:00<00:00, 33.16 Batches/s]04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  55%|█████▌    | 22/40 [00:00<00:00, 32.67 Batches/s]04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples:  65%|██████▌   | 26/40 [00:00<00:00, 33.04 Batches/s]04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "04/16/2021 06:52:04 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:01<00:00, 35.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 50.33 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 47.27 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 49.26 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.25 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.86 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 50.10 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 49.74 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.24 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.28 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 48.47 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 48.87 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 48.79 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 44.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 46.27 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 48.26 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 46.97 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.67 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.30 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.10 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.08 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.85 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.12 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.65 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.69 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.36 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.28 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.37 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.49 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.01 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.21 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.64 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.54 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.41 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.20 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.30 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.47 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.16 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.10 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.21 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.22 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.58 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.13 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.19 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.51 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.08 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.08 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.15 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.95 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.82 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 52.03 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.78 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.94 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.94 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.74 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.71 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.98 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.90 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.87 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.94 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.73 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.93 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.75 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.60 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.88 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.82 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 40/40 [00:00<00:00, 51.75 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 35/35 [00:00<00:00, 51.58 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "# 9. Load it & harvest your fruits (Inference)\n",
    "save_dir =  \"/home/graphn/repositories/you_conscious/dl_xp/trained_models/category_v1.2\"\n",
    "basic_texts = []\n",
    "for t in texts:\n",
    "    basic_texts.append({\"text\":t})\n",
    "print(len(basic_texts))\n",
    "model = Inferencer.load(save_dir, gpu=True, return_class_probs=False,task_type=\"text_classification\")\n",
    "result = model.inference_from_dicts(dicts=basic_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions=[]\n",
    "i = 0\n",
    "for batch in result:\n",
    "    for x in batch[\"predictions\"]:\n",
    "        if True:\n",
    "            prediction = x[\"label\"]\n",
    "            predictions.append(prediction)\n",
    "        #probabilities = x[\"probability\"]\n",
    "        #position = np.argmax(probabilities)\n",
    "        #print(id_2_labels[position],y_true[i])\n",
    "        #labels = list(id_2_labels.values())\n",
    "        #predictions.append({label:prob for label,prob in zip(probabilities,labels)})\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bekleidung > Damen > T-Shirts & Blusen > T-Shirts',\n",
       " 'Bekleidung > Herren > T-Shirts & Hemden > T-Shirts']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate(predictions,Y_test):\n",
    "    return classification_report(predictions, Y_test,output_dict=True)#, target_names=target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/graphn/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/graphn/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/graphn/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/graphn/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/graphn/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/graphn/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluation=evaluate(predictions,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "supports = []\n",
    "labels = []\n",
    "for k,v in evaluation.items():\n",
    "    if type(v) != float: #!=\"accuracy\":\n",
    "        labels.append(k)\n",
    "        precisions.append(v[\"precision\"])\n",
    "        recalls.append(v[\"recall\"])\n",
    "        f1s.append(v[\"f1-score\"])\n",
    "        supports.append(v[\"support\"])\n",
    "x = pd.DataFrame({\"labels\":labels,\"precision\":precisions,\"recall\":recalls,\"f1_score\":f1s,\"support\":supports})\n",
    "x.to_csv(\"category_v1.2.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
